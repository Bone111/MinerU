# MinerU 2.5.3 ä½¿ç”¨æ–‡æ¡£

## ç®€ä»‹

MinerU æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ PDF æ–‡æ¡£è½¬ Markdown å·¥å…·ï¼Œæ”¯æŒæ–‡æœ¬ã€è¡¨æ ¼ã€å…¬å¼ã€å›¾åƒçš„æ™ºèƒ½è¯†åˆ«å’Œæå–ã€‚2.5.3 ç‰ˆæœ¬æä¾›äº†å®Œæ•´çš„ Docker åŒ–éƒ¨ç½²æ–¹æ¡ˆå’Œå¤šç§åç«¯æ”¯æŒã€‚

## å·¥ä½œç›®å½•ç»“æ„è¯´æ˜

MinerU 2.5.3 ç‰ˆæœ¬é‡‡ç”¨ç»Ÿä¸€çš„å·¥ä½œç›®å½•ç®¡ç†ï¼Œæ¨èçš„ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

```
./mineru-workspace/                    # ä¸»å·¥ä½œç›®å½•
â”œâ”€â”€ output/                           # MinerU APIæœåŠ¡è¾“å‡º
â”‚   â”œâ”€â”€ document1.md                  # è§£æåçš„Markdownæ–‡ä»¶
â”‚   â”œâ”€â”€ document1_content_list.json   # å†…å®¹åˆ—è¡¨
â”‚   â””â”€â”€ images/                       # æå–çš„å›¾ç‰‡
â”œâ”€â”€ logs/                             # MinerU APIæœåŠ¡æ—¥å¿—
â”‚   â”œâ”€â”€ mineru.log                    # åº”ç”¨æ—¥å¿—
â”‚   â””â”€â”€ error.log                     # é”™è¯¯æ—¥å¿—
â”œâ”€â”€ vlm-output/                       # VLMæœåŠ¡è¾“å‡º  
â”‚   â””â”€â”€ vlm_results/                  # VLMå¤„ç†ç»“æœ
â”œâ”€â”€ vlm-logs/                         # VLMæœåŠ¡æ—¥å¿—
â”‚   â”œâ”€â”€ vlm.log                       # VLMåº”ç”¨æ—¥å¿—
â”‚   â””â”€â”€ vlm_error.log                 # VLMé”™è¯¯æ—¥å¿—
â”œâ”€â”€ models/                           # AIæ¨¡å‹æ–‡ä»¶
â”‚   â”œâ”€â”€ layout_model/                 # å¸ƒå±€æ£€æµ‹æ¨¡å‹
â”‚   â”œâ”€â”€ ocr_model/                    # OCRæ¨¡å‹
â”‚   â””â”€â”€ vlm_model/                    # è§†è§‰è¯­è¨€æ¨¡å‹
â””â”€â”€ pdfs/                             # åŸå§‹PDFæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
```

### ğŸ¯ ç›®å½•è¯´æ˜

- **output/**: MinerU APIæœåŠ¡çš„è§£æç»“æœå­˜å‚¨ç›®å½•
- **logs/**: MinerU APIæœåŠ¡çš„è¿è¡Œæ—¥å¿—ç›®å½•
- **vlm-output/**: VLMæœåŠ¡çš„å¤„ç†ç»“æœå­˜å‚¨ç›®å½•
- **vlm-logs/**: VLMæœåŠ¡çš„è¿è¡Œæ—¥å¿—ç›®å½•
- **models/**: æ‰€æœ‰AIæ¨¡å‹æ–‡ä»¶çš„ç»Ÿä¸€å­˜å‚¨ç›®å½•
- **pdfs/**: å¯é€‰çš„PDFæºæ–‡ä»¶å­˜å‚¨ç›®å½•

## å¿«é€Ÿéƒ¨ç½²

### æ–¹æ³•ä¸€ï¼šä½¿ç”¨ Dockerï¼ˆæ¨èï¼‰

#### å›½é™…ç‰ˆæœ¬

```bash
git clone https://github.com/opendatalab/MinerU.git -b release-2.5.3
cd MinerU/docker/global
docker build -t mineru:2.5.3 .
```

#### å›½å†…ç‰ˆæœ¬ï¼ˆåŠ é€Ÿé•œåƒï¼‰

```bash
git clone https://github.com/opendatalab/MinerU.git -b release-2.5.3
cd MinerU/docker/china
docker build -t mineru:2.5.3-v100 .
```

### æ–¹æ³•äºŒï¼šæºç å®‰è£…

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# å®‰è£… MinerU
pip install 'mineru[core]==2.5.3'

# ä¸‹è½½æ¨¡å‹
mineru-models-download -s huggingface -m all  # å›½é™…
# æˆ–
mineru-models-download -s modelscope -m all   # å›½å†…
```

## æœåŠ¡å¯åŠ¨

### API æœåŠ¡ï¼ˆæ¨èï¼‰

#### åŸºç¡€å¯åŠ¨

```bash
# åˆ›å»ºMinerUå·¥ä½œç›®å½•ç»“æ„
mkdir -p ./mineru-workspace/output ./mineru-workspace/logs

# å¯åŠ¨ MinerU API æœåŠ¡
docker run --rm -it --gpus all -p 8000:8000 \
  --name mineru-api \
  -v $(pwd)/mineru-workspace/output:/app/output \
  -v $(pwd)/mineru-workspace/logs:/app/logs \
  mineru:2.5.3-v100 \
  mineru-api --host 0.0.0.0 --port 8000

# è®¿é—® API æ–‡æ¡£
# http://localhost:8000/docs
```

#### ç”Ÿäº§ç¯å¢ƒå¯åŠ¨

##### é€šç”¨é…ç½®

```bash
# åˆ›å»ºMinerUå·¥ä½œç›®å½•ç»“æ„
mkdir -p ./mineru-workspace/output ./mineru-workspace/logs

# åå°è¿è¡Œï¼Œè‡ªåŠ¨é‡å¯ï¼Œé™åˆ¶èµ„æº
docker run -d --restart=unless-stopped \
  --name mineru-api-prod \
  --gpus all \
  -p 8000:8000 \
  -v $(pwd)/mineru-workspace/output:/app/output \
  -v $(pwd)/mineru-workspace/logs:/app/logs \
  --memory=8g \
  --cpus=4 \
  -e WORKERS=4 \
  -e LOG_LEVEL=info \
  mineru:2.5.3-v100 \
  mineru-api --host 0.0.0.0 --port 8000 --workers 4
```

##### T4æ˜¾å¡ä¼˜åŒ–é…ç½®ï¼ˆ15Gæ˜¾å­˜ + 60Gå†…å­˜ï¼‰

```bash
# åˆ›å»ºMinerUå·¥ä½œç›®å½•ç»“æ„
mkdir -p ./mineru-workspace/output ./mineru-workspace/logs

# T4æ˜¾å¡ä¼˜åŒ–å¯åŠ¨ï¼ˆæ¨èé…ç½®ï¼‰
docker run -d --restart=unless-stopped \
  --name mineru-api-prod \
  --gpus all \
  -p 8000:8000 \
  -v $(pwd)/mineru-workspace/output:/app/output \
  -v $(pwd)/mineru-workspace/logs:/app/logs \
  --memory=24g \
  --cpus=8 \
  --shm-size=4g \
  -e WORKERS=6 \
  -e LOG_LEVEL=info \
  -e PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512,expandable_segments:True \
  -e CUDA_VISIBLE_DEVICES=0 \
  mineru:2.5.3-v100 \
  mineru-api --host 0.0.0.0 --port 8000 --workers 6
```

##### ç¨³å®šæ€§ä¼˜å…ˆé…ç½®ï¼ˆä¿å®ˆé…ç½®ï¼‰

```bash
# åˆ›å»ºMinerUå·¥ä½œç›®å½•ç»“æ„
mkdir -p ./mineru-workspace/output ./mineru-workspace/logs

# ç¨³å®šæ€§ä¼˜å…ˆï¼Œé€‚åˆé•¿æœŸè¿è¡Œ
docker run -d --restart=unless-stopped \
  --name mineru-api-prod \
  --gpus all \
  -p 8000:8000 \
  -v $(pwd)/mineru-workspace/output:/app/output \
  -v $(pwd)/mineru-workspace/logs:/app/logs \
  --memory=16g \
  --cpus=6 \
  --shm-size=2g \
  -e WORKERS=4 \
  -e LOG_LEVEL=info \
  -e PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:256 \
  mineru:2.5.3-v100 \
  mineru-api --host 0.0.0.0 --port 8000 --workers 4
```

##### Tesla V100åŒGPUä¼˜åŒ–é…ç½®ï¼ˆé«˜æ€§èƒ½æœåŠ¡å™¨ï¼‰

```bash
# åˆ›å»ºMinerUå·¥ä½œç›®å½•ç»“æ„
mkdir -p ./mineru-workspace/output ./mineru-workspace/logs ./mineru-workspace/models

# Tesla V100åŒGPUä¼˜åŒ–å¯åŠ¨ï¼ˆé€‚ç”¨äº2Ã—V100-32GB + 125GBå†…å­˜æœåŠ¡å™¨ï¼‰
# æ¨èåœ¨ä¸“é—¨çš„å·¥ä½œç›®å½•ä¸­è¿è¡Œï¼Œä¾‹å¦‚ï¼š/home/username/å·¥ä½œç›®å½•
docker run -d --restart=unless-stopped \
  --name mineru-api-v100 \
  --gpus all \
  -p 8000:8000 \
  -v $(pwd)/mineru-workspace/output:/app/output \
  -v $(pwd)/mineru-workspace/logs:/app/logs \
  --memory=48g \
  --cpus=16 \
  --shm-size=8g \
  -e WORKERS=8 \
  -e LOG_LEVEL=info \
  -e PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024,expandable_segments:True \
  -e CUDA_VISIBLE_DEVICES=1 \
  -e OMP_NUM_THREADS=16 \
  -e MKL_NUM_THREADS=16 \
  mineru:2.5.3-v100 \
  mineru-api --host 0.0.0.0 --port 8000 --workers 8

# ä½¿ç”¨GPU 1ï¼ˆå› ä¸ºGPU 0å¯èƒ½å·²æœ‰å…¶ä»–ä»»åŠ¡å ç”¨å†…å­˜ï¼‰
# å¦‚æœéœ€è¦ä½¿ç”¨ä¸¤ä¸ªGPUè¿›è¡Œè´Ÿè½½å‡è¡¡ï¼Œå¯ä»¥ç§»é™¤CUDA_VISIBLE_DEVICESé™åˆ¶
```

##### Tesla V100åŒGPUè´Ÿè½½å‡è¡¡é…ç½®

```bash
# åˆ›å»ºMinerUå·¥ä½œç›®å½•ç»“æ„
mkdir -p ./mineru-workspace/output ./mineru-workspace/logs ./mineru-workspace/models

# V100åŒGPUè´Ÿè½½å‡è¡¡ï¼ˆå¦‚æœGPU 0çš„ä»»åŠ¡å¯ä»¥å…±äº«ï¼‰
docker run -d --restart=unless-stopped \
  --name mineru-api-v100-dual \
  --gpus all \
  -p 8000:8000 \
  -v $(pwd)/mineru-workspace/output:/app/output \
  -v $(pwd)/mineru-workspace/logs:/app/logs \
  --memory=64g \
  --cpus=20 \
  --shm-size=16g \
  -e WORKERS=10 \
  -e LOG_LEVEL=info \
  -e PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024,expandable_segments:True \
  -e OMP_NUM_THREADS=20 \
  -e MKL_NUM_THREADS=20 \
  mineru:2.5.3-v100 \
  mineru-api --host 0.0.0.0 --port 8000 --workers 10
```

### VLM æœåŠ¡ï¼ˆè§†è§‰è¯­è¨€æ¨¡å‹ï¼‰

#### æ ‡å‡†é…ç½®

```bash
# åˆ›å»ºVLMå·¥ä½œç›®å½•ç»“æ„
mkdir -p ./mineru-workspace/vlm-output ./mineru-workspace/vlm-logs ./mineru-workspace/models

# å¯åŠ¨ vLLM æœåŠ¡ï¼ˆOpenAI å…¼å®¹ï¼‰
docker run --rm -it --gpus all -p 30000:30000 \
  --name mineru-vlm \
  --shm-size=16g \
  -v $(pwd)/mineru-workspace/models:/app/models \
  -v $(pwd)/mineru-workspace/vlm-output:/app/output \
  -v $(pwd)/mineru-workspace/vlm-logs:/app/logs \
  mineru:2.5.3-v100 \
  mineru-vllm-server --host 0.0.0.0 --port 30000
```

#### é«˜æ€§èƒ½é…ç½®

```bash
# åˆ›å»ºVLMå·¥ä½œç›®å½•ç»“æ„
mkdir -p ./mineru-workspace/vlm-output ./mineru-workspace/vlm-logs ./mineru-workspace/models

# é«˜æ€§èƒ½é…ç½®ï¼ˆå¤š GPUã€å¤§å†…å­˜ï¼‰
docker run --rm -it --gpus all -p 30000:30000 \
  --name mineru-vlm-hp \
  --shm-size=32g \
  -v $(pwd)/mineru-workspace/models:/app/models \
  -v $(pwd)/mineru-workspace/vlm-output:/app/output \
  -v $(pwd)/mineru-workspace/vlm-logs:/app/logs \
  -e CUDA_VISIBLE_DEVICES=0,1 \
  mineru:2.5.3-v100 \
  mineru-vllm-server \
    --host 0.0.0.0 \
    --port 30000 \
    --gpu-memory-utilization 0.9 \
    --max-model-len 32768 \
    --tensor-parallel-size 2
```

#### ä½èµ„æºé…ç½®

```bash
# åˆ›å»ºVLMå·¥ä½œç›®å½•ç»“æ„
mkdir -p ./mineru-workspace/vlm-output ./mineru-workspace/vlm-logs ./mineru-workspace/models

# ä½èµ„æºé…ç½®ï¼ˆå• GPUã€èŠ‚çœå†…å­˜ï¼‰
docker run --rm -it --gpus '"device=0"' -p 30000:30000 \
  --name mineru-vlm-lite \
  --shm-size=8g \
  -v $(pwd)/mineru-workspace/models:/app/models \
  -v $(pwd)/mineru-workspace/vlm-output:/app/output \
  -v $(pwd)/mineru-workspace/vlm-logs:/app/logs \
  mineru:2.5.3-v100 \
  mineru-vllm-server \
    --host 0.0.0.0 \
    --port 30000 \
    --gpu-memory-utilization 0.6 \
    --max-model-len 8192
```

#### Tesla V100åŒGPUé…ç½®ï¼ˆæ¨èç”¨äºæ‚¨çš„æœåŠ¡å™¨ï¼‰

```bash
# åˆ›å»ºVLMå·¥ä½œç›®å½•ç»“æ„
mkdir -p ./mineru-workspace/vlm-output ./mineru-workspace/vlm-logs ./mineru-workspace/models

# V100å•GPUé…ç½®ï¼ˆä½¿ç”¨GPU 1ï¼Œé¿å…ä¸ç°æœ‰ä»»åŠ¡å†²çªï¼‰
docker run -d --restart=unless-stopped \
  --name mineru-vlm-v100-single \
  --gpus '"device=1"' \
  -p 30000:30000 \
  --shm-size=16g \
  -v $(pwd)/mineru-workspace/models:/app/models \
  -v $(pwd)/mineru-workspace/vlm-output:/app/output \
  -v $(pwd)/mineru-workspace/vlm-logs:/app/logs \
  --memory=32g \
  -e CUDA_VISIBLE_DEVICES=1 \
  mineru:2.5.3-v100 \
  mineru-vllm-server \
    --host 0.0.0.0 \
    --port 30000 \
    --gpu-memory-utilization 0.85 \
    --max-model-len 32768

# V100åŒGPUé…ç½®ï¼ˆå¦‚æœå¯ä»¥ä¸GPU 0çš„ä»»åŠ¡å…±å­˜ï¼‰
docker run -d --restart=unless-stopped \
  --name mineru-vlm-v100-dual \
  --gpus all \
  -p 30001:30000 \
  --shm-size=32g \
  -v $(pwd)/mineru-workspace/models:/app/models \
  -v $(pwd)/mineru-workspace/vlm-output:/app/output \
  -v $(pwd)/mineru-workspace/vlm-logs:/app/logs \
  --memory=48g \
  mineru:2.5.3-v100 \
  mineru-vllm-server \
    --host 0.0.0.0 \
    --port 30000 \
    --gpu-memory-utilization 0.7 \
    --max-model-len 65536 \
    --tensor-parallel-size 2
```

### Gradio Web ç•Œé¢

#### æ ‡å‡†å¯åŠ¨

```bash
# åˆ›å»ºMinerUå·¥ä½œç›®å½•ç»“æ„
mkdir -p ./mineru-workspace/output ./mineru-workspace/logs

# å¯åŠ¨ Web ç•Œé¢
docker run --rm -it --gpus all -p 8000:8000 \
  --name mineru-gradio \
  -v $(pwd)/mineru-workspace/output:/app/output \
  -v $(pwd)/mineru-workspace/logs:/app/logs \
  mineru:2.5.3-v100 \
  mineru-gradio --server-name 0.0.0.0 --server-port 8000
```

#### å…¬ç½‘è®¿é—®é…ç½®

```bash
# åˆ›å»ºMinerUå·¥ä½œç›®å½•ç»“æ„
mkdir -p ./mineru-workspace/output ./mineru-workspace/logs

# å¯ç”¨å…¬ç½‘è®¿é—®å’Œè®¤è¯
docker run --rm -it --gpus all -p 8000:8000 \
  --name mineru-gradio-public \
  -v $(pwd)/mineru-workspace/output:/app/output \
  -v $(pwd)/mineru-workspace/logs:/app/logs \
  -e GRADIO_SERVER_NAME=0.0.0.0 \
  -e GRADIO_AUTH=username:password \
  mineru:2.5.3-v100 \
  mineru-gradio \
    --server-name 0.0.0.0 \
    --server-port 8000 \
    --share \
    --auth username:password
```

## API ä½¿ç”¨

### æ–‡ä»¶è§£æ API

#### åŸºç¡€ç”¨æ³•

```bash
curl -X POST "http://localhost:8000/file_parse" \
  -H "Content-Type: multipart/form-data" \
  -F "files=@/path/to/your/file.pdf" \
  -F "backend=pipeline" \
  -F "parse_method=auto" \
  -F "lang_list=ch" \
  -F "return_md=true" \
  -F "response_format_zip=false"
```

#### è·å– ZIP å‹ç¼©ç»“æœ

```bash
curl -X POST "http://localhost:8000/file_parse" \
  -H "Content-Type: multipart/form-data" \
  -F "files=@/path/to/your/file.pdf" \
  -F "backend=pipeline" \
  -F "return_md=true" \
  -F "return_images=true" \
  -F "response_format_zip=true" \
  --output result.zip
```

#### æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶

```bash
curl -X POST "http://localhost:8000/file_parse" \
  -H "Content-Type: multipart/form-data" \
  -F "files=@/path/to/file1.pdf" \
  -F "files=@/path/to/file2.pdf" \
  -F "files=@/path/to/file3.pdf" \
  -F "backend=pipeline" \
  -F "lang_list=ch" \
  -F "lang_list=en" \
  -F "lang_list=ch" \
  -F "return_md=true"
```

#### ä½¿ç”¨ VLM åç«¯

```bash
curl -X POST "http://localhost:8000/file_parse" \
  -H "Content-Type: multipart/form-data" \
  -F "files=@/path/to/your/file.pdf" \
  -F "backend=vlm" \
  -F "server_url=http://localhost:30000/v1" \
  -F "lang_list=ch" \
  -F "return_md=true"
```

### VLM æœåŠ¡ API

#### æ–‡æœ¬å¯¹è¯

```bash
curl http://localhost:30000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-xxx" \
  -d '{
    "model": "auto",
    "messages": [{"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ çš„åŠŸèƒ½"}],
    "max_tokens": 200
  }'
```

#### å›¾åƒç†è§£

```bash
curl http://localhost:30000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-xxx" \
  -d '{
    "model": "auto",
    "messages": [{
      "role": "user",
      "content": [
        {"type": "text", "text": "è¯·åˆ†æè¿™å¼ å›¾ç‰‡ä¸­çš„æ–‡å­—å’Œè¡¨æ ¼"},
        {"type": "image_url", "image_url": {"url": "data:image/jpeg;base64,/9j/4AAQ..."}}
      ]
    }],
    "max_tokens": 500
  }'
```

#### Python SDK è°ƒç”¨

```python
from openai import OpenAI

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = OpenAI(
    base_url="http://localhost:30000/v1", 
    api_key="sk-xxx"
)

# æ–‡æœ¬å¯¹è¯
response = client.chat.completions.create(
    model="auto",
    messages=[{"role": "user", "content": "ä½ å¥½ï¼Œåšä¸ªè‡ªæˆ‘ä»‹ç»"}],
    max_tokens=200
)
print(response.choices[0].message.content)

# å›¾åƒç†è§£
response = client.chat.completions.create(
    model="auto",
    messages=[{
        "role": "user",
        "content": [
            {"type": "text", "text": "æè¿°è¿™å¼ å›¾ç‰‡"},
            {"type": "image_url", "image_url": {"url": "https://example.com/image.jpg"}}
        ]
    }],
    max_tokens=500
)
print(response.choices[0].message.content)
```

## å‚æ•°è¯´æ˜

### file_parse API å‚æ•°

| å‚æ•°                    | ç±»å‹     | é»˜è®¤å€¼     | è¯´æ˜                              |
| ----------------------- | -------- | ---------- | --------------------------------- |
| `files`               | File[]   | å¿…éœ€       | ä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆPDF/å›¾ç‰‡ï¼‰        |
| `backend`             | string   | "pipeline" | åç«¯ç±»å‹ï¼š"pipeline" æˆ– "vlm"     |
| `parse_method`        | string   | "auto"     | è§£ææ–¹æ³•ï¼š"auto", "ocr", "txt"    |
| `lang_list`           | string[] | ["ch"]     | è¯­è¨€åˆ—è¡¨ï¼šch, en, ja, ko ç­‰       |
| `formula_enable`      | bool     | true       | æ˜¯å¦å¯ç”¨å…¬å¼è¯†åˆ«                  |
| `table_enable`        | bool     | true       | æ˜¯å¦å¯ç”¨è¡¨æ ¼è¯†åˆ«                  |
| `return_md`           | bool     | true       | æ˜¯å¦è¿”å› Markdown æ ¼å¼            |
| `return_images`       | bool     | false      | æ˜¯å¦è¿”å›æå–çš„å›¾ç‰‡                |
| `return_middle_json`  | bool     | false      | æ˜¯å¦è¿”å›ä¸­é—´ JSON ç»“æœ            |
| `return_model_output` | bool     | false      | æ˜¯å¦è¿”å›æ¨¡å‹åŸå§‹è¾“å‡º              |
| `return_content_list` | bool     | false      | æ˜¯å¦è¿”å›å†…å®¹åˆ—è¡¨                  |
| `response_format_zip` | bool     | false      | æ˜¯å¦ä»¥ ZIP æ ¼å¼è¿”å›               |
| `start_page_id`       | int      | 0          | èµ·å§‹é¡µç                           |
| `end_page_id`         | int      | 99999      | ç»“æŸé¡µç                           |
| `server_url`          | string   | null       | VLM æœåŠ¡å™¨ URLï¼ˆä½¿ç”¨ vlm åç«¯æ—¶ï¼‰ |

### VLM æœåŠ¡å‚æ•°

| å‚æ•°                         | è¯´æ˜                                                 |
| ---------------------------- | ---------------------------------------------------- |
| `--port`                   | æœåŠ¡ç«¯å£ï¼ˆé»˜è®¤ï¼š30000ï¼‰                              |
| `--host`                   | ç»‘å®šåœ°å€ï¼ˆé»˜è®¤ï¼š127.0.0.1ï¼ŒDocker ä¸­å»ºè®®ç”¨ 0.0.0.0ï¼‰ |
| `--model`                  | æŒ‡å®šæ¨¡å‹è·¯å¾„ï¼ˆé»˜è®¤è‡ªåŠ¨ä¸‹è½½ï¼‰                         |
| `--gpu-memory-utilization` | GPU å†…å­˜åˆ©ç”¨ç‡ï¼ˆé»˜è®¤ï¼š0.5ï¼‰                          |

## å‘½ä»¤è¡Œå·¥å…·

### åŸºç¡€ä½¿ç”¨

```bash
# è§£æå•ä¸ªæ–‡ä»¶
mineru /path/to/file.pdf

# æŒ‡å®šè¾“å‡ºç›®å½•
mineru /path/to/file.pdf --output-dir ./output

# æ‰¹é‡å¤„ç†
mineru /path/to/files/*.pdf

# æŒ‡å®šè¯­è¨€
mineru /path/to/file.pdf --lang ch

# ä½¿ç”¨ VLM åç«¯
mineru /path/to/file.pdf --backend vlm --server-url http://localhost:30000/v1
```

### é«˜çº§é€‰é¡¹

```bash
# ç¦ç”¨å…¬å¼è¯†åˆ«
mineru /path/to/file.pdf --no-formula

# ç¦ç”¨è¡¨æ ¼è¯†åˆ«  
mineru /path/to/file.pdf --no-table

# æŒ‡å®šé¡µé¢èŒƒå›´
mineru /path/to/file.pdf --start-page 1 --end-page 10

# è¾“å‡ºé¢å¤–æ ¼å¼
mineru /path/to/file.pdf --dump-images --dump-middle-json
```

## æ”¯æŒçš„æ–‡ä»¶æ ¼å¼

- **PDF**: .pdf
- **Wordæ–‡æ¡£**: .doc, .docx
- **PowerPoint**: .ppt, .pptx
- **å›¾ç‰‡**: .jpg, .jpeg, .png, .bmp, .tiff, .webp

## æ”¯æŒçš„è¯­è¨€

- `ch`: ä¸­æ–‡
- `en`: è‹±æ–‡
- `ja`: æ—¥è¯­
- `ko`: éŸ©è¯­
- `ar`: é˜¿æ‹‰ä¼¯è¯­
- `hi`: å°åœ°è¯­
- `de`: å¾·è¯­
- `fr`: æ³•è¯­
- `ru`: ä¿„è¯­

## æ—¥å¿—ç®¡ç†å’Œç›‘æ§

### æŸ¥çœ‹å®¹å™¨æ—¥å¿—

#### å®æ—¶æŸ¥çœ‹æ—¥å¿—

```bash
# æŸ¥çœ‹APIæœåŠ¡æ—¥å¿—ï¼ˆå®æ—¶ï¼‰
docker logs -f mineru-api-prod

# æŸ¥çœ‹æœ€è¿‘100è¡Œæ—¥å¿—
docker logs --tail 100 mineru-api-prod

# æŸ¥çœ‹ç‰¹å®šæ—¶é—´æ®µçš„æ—¥å¿—
docker logs --since "2024-01-01T00:00:00" mineru-api-prod

# æŸ¥çœ‹VLMæœåŠ¡æ—¥å¿—
docker logs -f mineru-vlm
```

#### æŸ¥çœ‹æŒ‚è½½çš„æ—¥å¿—æ–‡ä»¶

```bash
# æŸ¥çœ‹åº”ç”¨æ—¥å¿—æ–‡ä»¶
tail -f ./logs/mineru.log
tail -f ./logs/error.log
tail -f ./logs/access.log

# æŸ¥çœ‹æ‰€æœ‰æ—¥å¿—æ–‡ä»¶
ls -la ./logs/

# æœç´¢é”™è¯¯æ—¥å¿—
grep -i error ./logs/*.log
grep -i "out of memory" ./logs/*.log
```

#### è¿›å…¥å®¹å™¨æŸ¥çœ‹

```bash
# è¿›å…¥å®¹å™¨
docker exec -it mineru-api-prod /bin/bash

# åœ¨å®¹å™¨å†…æŸ¥çœ‹æ—¥å¿—
cd /app/logs
ls -la
tail -f *.log

# æŸ¥çœ‹ç³»ç»Ÿèµ„æºä½¿ç”¨
top
free -h
nvidia-smi
```

### æ—¥å¿—æ¸…ç†å’Œç®¡ç†

#### æ¸…ç†æ—§æ—¥å¿—

```bash
# æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶å¤§å°
du -sh ./logs/*

# åˆ é™¤7å¤©å‰çš„æ—¥å¿—
find ./logs -name "*.log" -mtime +7 -delete

# å‹ç¼©æ—§æ—¥å¿—æ–‡ä»¶
find ./logs -name "*.log" -mtime +3 -exec gzip {} \;

# æ¸…ç†Dockerå®¹å™¨æ—¥å¿—ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰
docker logs --details mineru-api-prod 2>/dev/null | wc -l  # æŸ¥çœ‹æ—¥å¿—è¡Œæ•°
# å¦‚æœæ—¥å¿—è¿‡å¤§ï¼Œå¯ä»¥é‡å¯å®¹å™¨æ¥æ¸…ç†
docker restart mineru-api-prod
```

### ç›‘æ§å’Œè¯Šæ–­

#### å®¹å™¨çŠ¶æ€ç›‘æ§

```bash
# æŸ¥çœ‹å®¹å™¨çŠ¶æ€
docker ps --filter name=mineru-

# æŸ¥çœ‹å®¹å™¨èµ„æºä½¿ç”¨æƒ…å†µ
docker stats mineru-api-prod
docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}" mineru-api-prod

# æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ
nvidia-smi
watch -n 1 nvidia-smi  # æ¯ç§’åˆ·æ–°
```

#### å®¹å™¨å¥åº·æ£€æŸ¥

```bash
# æ£€æŸ¥å®¹å™¨è¿›ç¨‹
docker exec mineru-api-prod ps aux

# æ£€æŸ¥å®¹å™¨å†…å­˜ä½¿ç”¨
docker exec mineru-api-prod free -h

# æ£€æŸ¥å®¹å™¨ç£ç›˜ä½¿ç”¨
docker exec mineru-api-prod df -h

# æ£€æŸ¥APIæœåŠ¡æ˜¯å¦æ­£å¸¸
curl -s http://localhost:8000/docs
curl -s http://localhost:8000/health  # å¦‚æœæœ‰å¥åº·æ£€æŸ¥ç«¯ç‚¹

# æµ‹è¯•APIåŠŸèƒ½
curl -X POST "http://localhost:8000/file_parse" \
  -H "Content-Type: multipart/form-data" \
  -F "files=@test.pdf" \
  -F "backend=pipeline" \
  -F "parse_method=auto"
```

#### æ€§èƒ½åˆ†æ

```bash
# æŸ¥çœ‹å¤„ç†é˜Ÿåˆ—å’Œä»»åŠ¡çŠ¶æ€
curl -s http://localhost:8000/status  # å¦‚æœAPIæä¾›çŠ¶æ€ç«¯ç‚¹

# ç›‘æ§å¤„ç†æ—¶é—´
time curl -X POST "http://localhost:8000/file_parse" \
  -H "Content-Type: multipart/form-data" \
  -F "files=@test.pdf" \
  -F "backend=pipeline"

# æŸ¥çœ‹é”™è¯¯ç»Ÿè®¡
grep -c "ERROR" ./logs/*.log
grep -c "CUDA out of memory" ./logs/*.log
```

### æ—¥å¿—é…ç½®ä¼˜åŒ–

#### æ—¥å¿—è½®è½¬é…ç½®

```bash
# åˆ›å»ºlogrotateé…ç½®æ–‡ä»¶
sudo tee /etc/logrotate.d/mineru << EOF
/path/to/your/logs/*.log {
    daily
    missingok
    rotate 30
    compress
    notifempty
    create 0644 root root
    postrotate
        docker kill -s USR1 mineru-api-prod 2>/dev/null || true
    endscript
}
EOF

# æ‰‹åŠ¨æ‰§è¡Œæ—¥å¿—è½®è½¬
sudo logrotate -f /etc/logrotate.d/mineru
```

#### Dockeræ—¥å¿—é…ç½®

```bash
# å¯åŠ¨æ—¶é™åˆ¶æ—¥å¿—å¤§å°ï¼ˆæ·»åŠ åˆ°docker runå‘½ä»¤ï¼‰
--log-opt max-size=100m \
--log-opt max-file=5 \
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. onnxruntime å®‰è£…å¤±è´¥

**é—®é¢˜**ï¼š`onnxruntime>=1.17.1 has no wheels with a matching platform tag`

**è§£å†³æ–¹æ¡ˆ**ï¼š

- ä½¿ç”¨ Docker éƒ¨ç½²ï¼ˆæ¨èï¼‰
- æˆ–å‡çº§ç³»ç»Ÿ glibc åˆ° 2.27+
- æˆ–ä¿®æ”¹ä¾èµ–ç‰ˆæœ¬ä¸º onnxruntime==1.17.0

#### 2. GPU å†…å­˜ä¸è¶³

**ç°è±¡**ï¼š`CUDA out of memory`

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# åœæ­¢å…¶ä»– GPU è¿›ç¨‹
docker ps
docker stop <other_containers>

# é™ä½å†…å­˜ä½¿ç”¨
mineru-vllm-server --gpu-memory-utilization 0.3

# æˆ–ä½¿ç”¨ç¯å¢ƒå˜é‡
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
```

#### 3. ç«¯å£å†²çª

**é—®é¢˜**ï¼š`Address already in use`

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# æŸ¥çœ‹ç«¯å£å ç”¨
netstat -tlnp | grep :8000

# æ›´æ¢ç«¯å£
docker run ... -p 8080:8000 ...
```

#### 4. æ¨¡å‹ä¸‹è½½å¤±è´¥

**é—®é¢˜**ï¼šç½‘ç»œè¶…æ—¶æˆ–ä¸‹è½½ä¸­æ–­

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# ä½¿ç”¨å›½å†…é•œåƒ
mineru-models-download -s modelscope -m all

# æˆ–æ‰‹åŠ¨ä¸‹è½½åæŒ‡å®šè·¯å¾„
mineru --model-path /path/to/models
```

### æ€§èƒ½ä¼˜åŒ–

#### GPU ä¼˜åŒ–

```bash
# è®¾ç½®åˆé€‚çš„ batch size
export MINERU_BATCH_SIZE=4

# å¯ç”¨æ··åˆç²¾åº¦
export MINERU_FP16=true

# ä¼˜åŒ–å†…å­˜åˆ†é…
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
```

#### CPU ä¼˜åŒ–

```bash
# è®¾ç½®çº¿ç¨‹æ•°
export OMP_NUM_THREADS=8
export MKL_NUM_THREADS=8

# ç¦ç”¨ GPUï¼ˆä»…ä½¿ç”¨ CPUï¼‰
export CUDA_VISIBLE_DEVICES=""
```

## å¼€å‘é›†æˆ

### Python API

```python
import asyncio
from mineru.cli.common import aio_do_parse

async def parse_pdf():
    await aio_do_parse(
        output_dir="./output",
        pdf_file_names=["document"],
        pdf_bytes_list=[pdf_bytes],
        p_lang_list=["ch"],
        backend="pipeline",
        parse_method="auto",
        formula_enable=True,
        table_enable=True,
        f_dump_md=True
    )

# è¿è¡Œ
asyncio.run(parse_pdf())
```

### Docker Compose

```yaml
version: '3.8'
services:
  mineru-api:
    image: mineru:2.5.3-v100
    ports:
      - "8000:8000"
    command: mineru-api --host 0.0.0.0 --port 8000
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
  
  mineru-vllm:
    image: mineru:2.5.3-v100
    ports:
      - "30000:30000"
    command: mineru-vllm-server --host 0.0.0.0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

## ç‰ˆæœ¬ä¿¡æ¯

- **MinerU ç‰ˆæœ¬**: 2.5.3
- **åŸºç¡€é•œåƒ**: vllm/vllm-openai:v0.10.1.1
- **Python ç‰ˆæœ¬**: 3.10+
- **CUDA æ”¯æŒ**: æ˜¯
- **å¤šè¯­è¨€æ”¯æŒ**: æ˜¯

## å¿«é€Ÿå¯åŠ¨è„šæœ¬

### ä¸€é”®å¯åŠ¨è„šæœ¬

åˆ›å»º `start-mineru.sh` è„šæœ¬æ–‡ä»¶ï¼š

```bash
#!/bin/bash

# MinerU 2.5.3 ä¸€é”®å¯åŠ¨è„šæœ¬

set -e

# é…ç½®å‚æ•°
DOCKER_IMAGE="mineru:2.5.3-v100"
API_PORT=8000
VLM_PORT=30000
WORKSPACE_DIR="$(pwd)/mineru-workspace"
API_OUTPUT_DIR="$WORKSPACE_DIR/output"
API_LOGS_DIR="$WORKSPACE_DIR/logs"
VLM_OUTPUT_DIR="$WORKSPACE_DIR/vlm-output"
VLM_LOGS_DIR="$WORKSPACE_DIR/vlm-logs"
MODELS_DIR="$WORKSPACE_DIR/models"

# åˆ›å»ºå®Œæ•´çš„å·¥ä½œç›®å½•ç»“æ„
echo "åˆ›å»ºMinerUå·¥ä½œç›®å½•ç»“æ„åœ¨: $WORKSPACE_DIR"
mkdir -p "$API_OUTPUT_DIR" "$API_LOGS_DIR" "$VLM_OUTPUT_DIR" "$VLM_LOGS_DIR" "$MODELS_DIR"

# æ£€æŸ¥ Docker é•œåƒæ˜¯å¦å­˜åœ¨
if ! docker images | grep -q "$DOCKER_IMAGE"; then
    echo "Docker é•œåƒ $DOCKER_IMAGE ä¸å­˜åœ¨ï¼Œè¯·å…ˆæ„å»ºé•œåƒ"
    exit 1
fi

# åœæ­¢å·²å­˜åœ¨çš„å®¹å™¨
echo "åœæ­¢å·²å­˜åœ¨çš„å®¹å™¨..."
docker stop mineru-api mineru-vlm 2>/dev/null || true
docker rm mineru-api mineru-vlm 2>/dev/null || true

# å¯åŠ¨æœåŠ¡
echo "å¯åŠ¨ MinerU æœåŠ¡..."

# å¯åŠ¨ API æœåŠ¡
echo "å¯åŠ¨ MinerU API æœåŠ¡ (ç«¯å£: $API_PORT)..."
docker run -d --restart=unless-stopped \
  --name mineru-api \
  --gpus all \
  -p $API_PORT:8000 \
  -v "$API_OUTPUT_DIR:/app/output" \
  -v "$API_LOGS_DIR:/app/logs" \
  --memory=8g \
  --cpus=4 \
  "$DOCKER_IMAGE" \
  mineru-api --host 0.0.0.0 --port 8000 --workers 4

# å¯åŠ¨ VLM æœåŠ¡
echo "å¯åŠ¨ VLM æœåŠ¡ (ç«¯å£: $VLM_PORT)..."
docker run -d --restart=unless-stopped \
  --name mineru-vlm \
  --gpus all \
  -p $VLM_PORT:30000 \
  --shm-size=16g \
  -v "$MODELS_DIR:/app/models" \
  -v "$VLM_OUTPUT_DIR:/app/output" \
  -v "$VLM_LOGS_DIR:/app/logs" \
  "$DOCKER_IMAGE" \
  mineru-vllm-server --host 0.0.0.0 --port 30000

echo "æœåŠ¡å¯åŠ¨å®Œæˆï¼"
echo "API æœåŠ¡: http://localhost:$API_PORT/docs"
echo "VLM æœåŠ¡: http://localhost:$VLM_PORT/v1"
echo "æ£€æŸ¥æœåŠ¡çŠ¶æ€: docker ps"
```

ä½¿ç”¨æ–¹æ³•ï¼š

```bash
chmod +x start-mineru.sh
./start-mineru.sh
```

### Tesla V100æœåŠ¡å™¨ä¸“ç”¨å¯åŠ¨è„šæœ¬

åˆ›å»º `start-mineru-v100.sh` è„šæœ¬æ–‡ä»¶ï¼ˆé€‚ç”¨äºæ‚¨çš„æœåŠ¡å™¨é…ç½®ï¼‰ï¼š

```bash
#!/bin/bash

# MinerU 2.5.3 Tesla V100åŒGPUæœåŠ¡å™¨ä¸“ç”¨å¯åŠ¨è„šæœ¬

set -e

# é…ç½®å‚æ•°
DOCKER_IMAGE="mineru:2.5.3-v100"
API_PORT=8000
VLM_PORT=30000
BASE_DIR="$(pwd)"
WORKSPACE_DIR="$BASE_DIR/mineru-workspace"
API_OUTPUT_DIR="$WORKSPACE_DIR/output"
API_LOGS_DIR="$WORKSPACE_DIR/logs"
VLM_OUTPUT_DIR="$WORKSPACE_DIR/vlm-output"
VLM_LOGS_DIR="$WORKSPACE_DIR/vlm-logs"
MODELS_DIR="$WORKSPACE_DIR/models"

# æ˜¾ç¤ºå·¥ä½œç›®å½•ä¿¡æ¯
echo "å½“å‰åŸºç¡€ç›®å½•: $BASE_DIR"
echo "MinerUå·¥ä½œç›®å½•: $WORKSPACE_DIR"
echo "APIè¾“å‡ºç›®å½•: $API_OUTPUT_DIR"
echo "APIæ—¥å¿—ç›®å½•: $API_LOGS_DIR"
echo "VLMè¾“å‡ºç›®å½•: $VLM_OUTPUT_DIR"
echo "VLMæ—¥å¿—ç›®å½•: $VLM_LOGS_DIR"
echo "æ¨¡å‹ç›®å½•: $MODELS_DIR"
echo ""

# æ£€æŸ¥GPUçŠ¶æ€
echo "æ£€æŸ¥GPUçŠ¶æ€..."
nvidia-smi

# åˆ›å»ºå®Œæ•´çš„å·¥ä½œç›®å½•ç»“æ„
echo ""
echo "åˆ›å»ºMinerUå·¥ä½œç›®å½•ç»“æ„..."
mkdir -p "$API_OUTPUT_DIR" "$API_LOGS_DIR" "$VLM_OUTPUT_DIR" "$VLM_LOGS_DIR" "$MODELS_DIR"

# æ£€æŸ¥ Docker é•œåƒæ˜¯å¦å­˜åœ¨
if ! docker images | grep -q "$DOCKER_IMAGE"; then
    echo "Docker é•œåƒ $DOCKER_IMAGE ä¸å­˜åœ¨ï¼Œè¯·å…ˆæ„å»ºé•œåƒ"
    exit 1
fi

# åœæ­¢å·²å­˜åœ¨çš„å®¹å™¨
echo "åœæ­¢å·²å­˜åœ¨çš„å®¹å™¨..."
docker stop mineru-api-v100 mineru-vlm-v100 2>/dev/null || true
docker rm mineru-api-v100 mineru-vlm-v100 2>/dev/null || true

# å¯åŠ¨æœåŠ¡
echo "å¯åŠ¨ MinerU V100 æœåŠ¡..."

# å¯åŠ¨ API æœåŠ¡ï¼ˆä½¿ç”¨GPU 1ï¼Œé¿å…ä¸GPU 0ç°æœ‰ä»»åŠ¡å†²çªï¼‰
echo "å¯åŠ¨ MinerU API æœåŠ¡ (ç«¯å£: $API_PORT, ä½¿ç”¨GPU 1)..."
docker run -d --restart=unless-stopped \
  --name mineru-api-v100 \
  --gpus all \
  -p $API_PORT:8000 \
  -v "$API_OUTPUT_DIR:/app/output" \
  -v "$API_LOGS_DIR:/app/logs" \
  --memory=48g \
  --cpus=16 \
  --shm-size=8g \
  -e WORKERS=8 \
  -e LOG_LEVEL=info \
  -e PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024,expandable_segments:True \
  -e CUDA_VISIBLE_DEVICES=1 \
  -e OMP_NUM_THREADS=16 \
  -e MKL_NUM_THREADS=16 \
  "$DOCKER_IMAGE" \
  mineru-api --host 0.0.0.0 --port 8000 --workers 8

# å¯åŠ¨ VLM æœåŠ¡ï¼ˆä½¿ç”¨GPU 1ï¼‰
echo "å¯åŠ¨ VLM æœåŠ¡ (ç«¯å£: $VLM_PORT, ä½¿ç”¨GPU 1)..."
docker run -d --restart=unless-stopped \
  --name mineru-vlm-v100 \
  --gpus '"device=1"' \
  -p $VLM_PORT:30000 \
  --shm-size=16g \
  -v "$MODELS_DIR:/app/models" \
  -v "$VLM_OUTPUT_DIR:/app/output" \
  -v "$VLM_LOGS_DIR:/app/logs" \
  --memory=32g \
  -e CUDA_VISIBLE_DEVICES=1 \
  "$DOCKER_IMAGE" \
  mineru-vllm-server \
    --host 0.0.0.0 \
    --port 30000 \
    --gpu-memory-utilization 0.85 \
    --max-model-len 32768

echo "V100æœåŠ¡å™¨ä¸“ç”¨é…ç½®å¯åŠ¨å®Œæˆï¼"
echo "API æœåŠ¡: http://localhost:$API_PORT/docs"
echo "VLM æœåŠ¡: http://localhost:$VLM_PORT/v1"
echo ""
echo "å½“å‰GPUä½¿ç”¨æƒ…å†µï¼š"
nvidia-smi
echo ""
echo "æ£€æŸ¥æœåŠ¡çŠ¶æ€: docker ps --filter name=mineru-"
echo "æŸ¥çœ‹APIæ—¥å¿—: docker logs -f mineru-api-v100"
echo "æŸ¥çœ‹VLMæ—¥å¿—: docker logs -f mineru-vlm-v100"
```

ä½¿ç”¨æ–¹æ³•ï¼š

```bash
chmod +x start-mineru-v100.sh
./start-mineru-v100.sh
```

### æœåŠ¡ç®¡ç†è„šæœ¬

åˆ›å»º `manage-mineru.sh` è„šæœ¬æ–‡ä»¶ï¼š

```bash
#!/bin/bash

# MinerU æœåŠ¡ç®¡ç†è„šæœ¬

case "$1" in
  start)
    echo "å¯åŠ¨ MinerU æœåŠ¡..."
    ./start-mineru.sh
    ;;
  stop)
    echo "åœæ­¢ MinerU æœåŠ¡..."
    docker stop mineru-api mineru-vlm mineru-gradio 2>/dev/null || true
    echo "æœåŠ¡å·²åœæ­¢"
    ;;
  restart)
    echo "é‡å¯ MinerU æœåŠ¡..."
    $0 stop
    sleep 2
    $0 start
    ;;
  status)
    echo "MinerU æœåŠ¡çŠ¶æ€ï¼š"
    docker ps --filter name=mineru- --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
    ;;
  logs)
    if [ -z "$2" ]; then
      echo "ç”¨æ³•: $0 logs [api|vlm|gradio]"
      exit 1
    fi
    docker logs -f "mineru-$2"
    ;;
  clean)
    echo "æ¸…ç† MinerU å®¹å™¨å’Œå·..."
    docker stop $(docker ps -q --filter name=mineru-) 2>/dev/null || true
    docker rm $(docker ps -aq --filter name=mineru-) 2>/dev/null || true
    echo "æ¸…ç†å®Œæˆ"
    ;;
  *)
    echo "ç”¨æ³•: $0 {start|stop|restart|status|logs|clean}"
    echo "  start   - å¯åŠ¨æ‰€æœ‰æœåŠ¡"
    echo "  stop    - åœæ­¢æ‰€æœ‰æœåŠ¡"
    echo "  restart - é‡å¯æ‰€æœ‰æœåŠ¡"
    echo "  status  - æŸ¥çœ‹æœåŠ¡çŠ¶æ€"
    echo "  logs    - æŸ¥çœ‹æœåŠ¡æ—¥å¿— (éœ€æŒ‡å®šæœåŠ¡å: api/vlm/gradio)"
    echo "  clean   - æ¸…ç†æ‰€æœ‰å®¹å™¨"
    exit 1
    ;;
esac
```

ä½¿ç”¨æ–¹æ³•ï¼š

```bash
chmod +x manage-mineru.sh
./manage-mineru.sh start    # å¯åŠ¨æœåŠ¡
./manage-mineru.sh status   # æŸ¥çœ‹çŠ¶æ€
./manage-mineru.sh logs api # æŸ¥çœ‹ API æ—¥å¿—
./manage-mineru.sh stop     # åœæ­¢æœåŠ¡
```

### å¥åº·æ£€æŸ¥è„šæœ¬

åˆ›å»º `health-check.sh` è„šæœ¬æ–‡ä»¶ï¼š

```bash
#!/bin/bash

# MinerU å¥åº·æ£€æŸ¥è„šæœ¬

API_URL="http://localhost:8000"
VLM_URL="http://localhost:30000"

echo "æ£€æŸ¥ MinerU æœåŠ¡å¥åº·çŠ¶æ€..."

# æ£€æŸ¥ API æœåŠ¡
echo -n "API æœåŠ¡: "
if curl -s "$API_URL/health" >/dev/null 2>&1; then
    echo "âœ… æ­£å¸¸"
else
    echo "âŒ å¼‚å¸¸"
fi

# æ£€æŸ¥ VLM æœåŠ¡
echo -n "VLM æœåŠ¡: "
if curl -s "$VLM_URL/health" >/dev/null 2>&1; then
    echo "âœ… æ­£å¸¸"
else
    echo "âŒ å¼‚å¸¸"
fi

# æ£€æŸ¥å®¹å™¨çŠ¶æ€
echo -e "\nå®¹å™¨çŠ¶æ€ï¼š"
docker ps --filter name=mineru- --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"

# æ£€æŸ¥èµ„æºä½¿ç”¨
echo -e "\nèµ„æºä½¿ç”¨ï¼š"
docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}" $(docker ps -q --filter name=mineru-)
```

ä½¿ç”¨æ–¹æ³•ï¼š

```bash
chmod +x health-check.sh
./health-check.sh
```

## é’ˆå¯¹æ‚¨æœåŠ¡å™¨çš„æ¨èé…ç½®

æ ¹æ®æ‚¨çš„æœåŠ¡å™¨é…ç½®ï¼ˆ2Ã—Tesla V100-32GB GPU + 125GBå†…å­˜ï¼‰ï¼Œä»¥ä¸‹æ˜¯æœ€ä½³å®è·µï¼š

### ğŸ¯ æ¨èçš„å¯åŠ¨å‘½ä»¤

ç”±äºæ‚¨çš„GPU 0å·²è¢«å ç”¨ï¼ˆ22GB/32GBï¼‰ï¼Œå»ºè®®ä½¿ç”¨GPU 1è¿è¡ŒMinerUï¼š

#### 1. APIæœåŠ¡å¯åŠ¨ï¼ˆæ¨èï¼‰

```bash
# åˆ›å»ºMinerUå·¥ä½œç›®å½•ç»“æ„  
mkdir -p ./mineru-workspace/output ./mineru-workspace/logs ./mineru-workspace/models

docker run -d --restart=unless-stopped \
  --name mineru-api-v100 \
  --gpus all \
  -p 8000:8000 \
  -v $(pwd)/mineru-workspace/output:/app/output \
  -v $(pwd)/mineru-workspace/logs:/app/logs \
  --memory=48g \
  --cpus=16 \
  --shm-size=8g \
  -e WORKERS=8 \
  -e LOG_LEVEL=info \
  -e PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024,expandable_segments:True \
  -e CUDA_VISIBLE_DEVICES=1 \
  -e OMP_NUM_THREADS=16 \
  -e MKL_NUM_THREADS=16 \
  mineru:2.5.3-v100 \
  mineru-api --host 0.0.0.0 --port 8000 --workers 8
```

#### 2. VLMæœåŠ¡å¯åŠ¨

```bash
docker run -d --restart=unless-stopped \
  --name mineru-vlm-v100 \
  --gpus '"device=1"' \
  -p 30000:30000 \
  --shm-size=16g \
  -v $(pwd)/mineru-workspace/models:/app/models \
  -v $(pwd)/mineru-workspace/vlm-output:/app/output \
  -v $(pwd)/mineru-workspace/vlm-logs:/app/logs \
  --memory=32g \
  -e CUDA_VISIBLE_DEVICES=1 \
  mineru:2.5.3-v100 \
  mineru-vllm-server \
    --host 0.0.0.0 \
    --port 30000 \
    --gpu-memory-utilization 0.85 \
    --max-model-len 32768
```

### âš¡ é…ç½®è¦ç‚¹

- **ç›®å½•ç»“æ„**ï¼šç»Ÿä¸€ä½¿ç”¨ `mineru-workspace/` ä½œä¸ºä¸»å·¥ä½œç›®å½•
- **æœåŠ¡åˆ†ç¦»**ï¼š
  - MinerU API â†’ `output/` å’Œ `logs/`
  - VLMæœåŠ¡ â†’ `vlm-output/` å’Œ `vlm-logs/`
- **GPUä½¿ç”¨**ï¼šä¸“ç”¨GPU 1ï¼ˆé¿å…ä¸GPU 0å†²çªï¼‰
- **å†…å­˜åˆ†é…**ï¼šAPIæœåŠ¡48GB + VLMæœåŠ¡32GBï¼Œå……åˆ†åˆ©ç”¨æ‚¨çš„125GBå¤§å†…å­˜
- **å¹¶å‘å¤„ç†**ï¼š8ä¸ªworkerè¿›ç¨‹ï¼ŒåŒ¹é…V100çš„å¼ºå¤§æ€§èƒ½
- **å†…å­˜ä¼˜åŒ–**ï¼šä½¿ç”¨å¤§å®¹é‡shared memoryå’Œexpandable segments

### ğŸ“Š æ€§èƒ½ç›‘æ§

å¯åŠ¨æœåŠ¡åï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç›‘æ§ï¼š

```bash
# æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ
nvidia-smi

# æŸ¥çœ‹å®¹å™¨çŠ¶æ€
docker ps --filter name=mineru-

# æŸ¥çœ‹èµ„æºä½¿ç”¨
docker stats mineru-api-v100 mineru-vlm-v100

# æŸ¥çœ‹å·¥ä½œç›®å½•ç»“æ„
ls -la ./mineru-workspace/
tree ./mineru-workspace/

# æŸ¥çœ‹MinerU APIæ—¥å¿—
docker logs -f mineru-api-v100
tail -f ./mineru-workspace/logs/*.log

# æŸ¥çœ‹VLMæœåŠ¡æ—¥å¿—
docker logs -f mineru-vlm-v100
tail -f ./mineru-workspace/vlm-logs/*.log

# æŸ¥çœ‹è¾“å‡ºç»“æœ
ls -la ./mineru-workspace/output/        # MinerUè§£æç»“æœ
ls -la ./mineru-workspace/vlm-output/    # VLMå¤„ç†ç»“æœ
```

### ğŸ”§ æ•…éšœæ’é™¤

å¦‚æœé‡åˆ°å†…å­˜ä¸è¶³ï¼š

```bash
# é™ä½å†…å­˜ä½¿ç”¨
docker update --memory=32g mineru-api-v100
```

å¦‚æœéœ€è¦ä½¿ç”¨åŒGPUï¼š

```bash
# ç§»é™¤CUDA_VISIBLE_DEVICESé™åˆ¶
-e CUDA_VISIBLE_DEVICES=0,1 \
```

## æ›´å¤šèµ„æº

- **å®˜æ–¹ç½‘ç«™**: https://mineru.net/
- **æ–‡æ¡£**: https://opendatalab.github.io/MinerU/
- **GitHub**: https://github.com/opendatalab/MinerU
- **é—®é¢˜åé¦ˆ**: https://github.com/opendatalab/MinerU/issues

---

*æœ€åæ›´æ–°ï¼š2025å¹´9æœˆ25æ—¥*
